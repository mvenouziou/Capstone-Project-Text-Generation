{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poetry_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUtE8N0zmCm0JFvh5nUmU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvenouziou/text_generator/blob/main/poetry_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TazS2ct_0bzD"
      },
      "source": [
        "# tensorflow modules\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "# for loading pre-trained BERT embeddings\r\n",
        "!pip install -q tensorflow-text  # need to install at each Google Colab session\r\n",
        "import tensorflow_text as text  \r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "# general modules\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import string"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf5IvArw4flU"
      },
      "source": [
        "# Load CSV and Split into train/test/validation sets\r\n",
        "def load_and_split_csv(select_column=False):\r\n",
        "    \"\"\" Loads data into train/test/validation sets \"\"\"\r\n",
        "\r\n",
        "    data_URL = 'https://raw.githubusercontent.com/mvenouziou' \\\r\n",
        "                + '/text_generator/main/robert_frost_collection.csv'\r\n",
        "\r\n",
        "    df = pd.read_csv(data_URL)\r\n",
        "\r\n",
        "    if select_column:\r\n",
        "        df = df[[select_column]]\r\n",
        "    \r\n",
        "    train_df, test_df, _, _ = \\\r\n",
        "        train_test_split(df, df, test_size=0.3, random_state=42)\r\n",
        "\r\n",
        "    test_df, valid_df, _, _ = \\\r\n",
        "        train_test_split(test_df, test_df, test_size=0.3, random_state=42)\r\n",
        "\r\n",
        "\r\n",
        "    return train_df, test_df, valid_df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eI9v5HK1gUsL",
        "outputId": "46dcc56a-b26f-4fdc-ea82-49aaff4e6764"
      },
      "source": [
        "train_df, test_df, valid_df = load_and_split_csv(select_column=False)\r\n",
        "train_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Collection</th>\n",
              "      <th>Year of Publication</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>A Late Walk</td>\n",
              "      <td>When I go up through the mowing field,\\nThe he...</td>\n",
              "      <td>A boy's Will</td>\n",
              "      <td>1913.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>My Butterfly</td>\n",
              "      <td>Thine emulous fond flowers are dead, too,\\r\\nA...</td>\n",
              "      <td>A boy's Will</td>\n",
              "      <td>1913.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Good Hours</td>\n",
              "      <td>I had for my winter evening walk- \\nNo one at ...</td>\n",
              "      <td>North of Boston</td>\n",
              "      <td>1914.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Meeting and Passing</td>\n",
              "      <td>As I went down the hill along the wall\\nThere ...</td>\n",
              "      <td>Mountain Interval</td>\n",
              "      <td>1916.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Asking for Roses</td>\n",
              "      <td>A house that lacks, seemingly, mistress and ma...</td>\n",
              "      <td>A boy's Will</td>\n",
              "      <td>1913.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Name   ... Year of Publication\n",
              "33          A Late Walk  ...              1913.0\n",
              "55         My Butterfly  ...              1913.0\n",
              "69           Good Hours  ...              1914.0\n",
              "28  Meeting and Passing  ...              1916.0\n",
              "40     Asking for Roses  ...              1913.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFq9YvqL470o"
      },
      "source": [
        "# clean dataset\r\n",
        "def clean_text(df, column='Content', dropna=True):\r\n",
        "    \"\"\" initial text data prep \"\"\"\r\n",
        "    \r\n",
        "    # drop missing values\r\n",
        "    if dropna:\r\n",
        "        df.dropna()\r\n",
        "\r\n",
        "    # add 'EOL' (end of line), poetry breaks without a separating punctiation)\r\n",
        "    df[[column]] = df[[column]].apply(lambda x: x.replace('\\n', ' EOL '))\r\n",
        "\r\n",
        "    # vocab to pad punctuation with spaces\r\n",
        "    spaced_punctuation = \\\r\n",
        "        list(map(lambda x: ' '.join(['', x, '']), string.punctuation))\r\n",
        "\r\n",
        "    # separate punctuation from words with extra spacing\r\n",
        "    for punc, space_punc in zip(string.punctuation, spaced_punctuation):\r\n",
        "        df[[column]] = df[[column]].apply(lambda x: x.replace(punc, space_punc))\r\n",
        "\r\n",
        "    # remove any excess spaces created above\r\n",
        "    for _ in range(3):\r\n",
        "        df[[column]] = df[[column]].apply(lambda x: x.replace('  ', ' '))\r\n",
        "        \r\n",
        "    return None  # changes reflected in (mutable) dataframe"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJmBADIz9U-w"
      },
      "source": [
        "def create_Xy_df(text):\r\n",
        "    \"\"\" Breaks a single text input into model inputs X and model outputs y. \r\n",
        "    Left side of text becomes X, the right side is our intended prediction, y\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # split sentence into words\r\n",
        "    split_text = text.split()\r\n",
        "\r\n",
        "    # group words into all possible left/right splits\r\n",
        "    # stores result in dataframe 'Xy_df'\r\n",
        "    Xy_df = pd.DataFrame(columns=['X', 'y'])\r\n",
        "    for i in range(1, len(split_text)):\r\n",
        "        x = split_text[: i]\r\n",
        "        y = split_text[i: ]\r\n",
        "    \r\n",
        "        # recombine to form X and y halves\r\n",
        "        X_section = ' '.join(x)\r\n",
        "        y_section = ' '.join(y)\r\n",
        "\r\n",
        "        Xy_df.loc[i] = [X_section, y_section]\r\n",
        "        \r\n",
        "    return Xy_df\r\n",
        "    \r\n",
        "\r\n",
        "def split_x_y(df):\r\n",
        "    \"\"\" Breaks full dataset's text into model inputs X and model outputs y \"\"\"\r\n",
        "    \r\n",
        "    # initialize empty dataframe\r\n",
        "    full_df = pd.DataFrame(columns=['X', 'y'])\r\n",
        "\r\n",
        "    # create X and y data for model\r\n",
        "    # by applying 'create_Xy_df' to each row of input df\r\n",
        "    for i in range(len(df)):\r\n",
        "        Xy_df = create_Xy_df(df.iloc[i][0])\r\n",
        "\r\n",
        "        full_df = pd.concat([full_df, Xy_df])\r\n",
        "\r\n",
        "    # separate out X and y components\r\n",
        "    X = full_df['X']\r\n",
        "    y = full_df['y']\r\n",
        "\r\n",
        "    return X, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIhQvgTTPrIM"
      },
      "source": [
        "# create BERT encoding layer\r\n",
        "def BERT_encoding_layer(text_input):\r\n",
        "    \"\"\" Creates model layer for encoding text \r\n",
        "    using BERT word embeddings model \"\"\"\r\n",
        "    \r\n",
        "    # preprocessor: formats input text for use in BERT encoder\r\n",
        "    preprocessor = hub.KerasLayer(\r\n",
        "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\")\r\n",
        "    encoder_inputs = preprocessor(text_input)\r\n",
        "\r\n",
        "    # initialize encoder\r\n",
        "    encoder = hub.KerasLayer(\r\n",
        "        \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\r\n",
        "        trainable=False)\r\n",
        "    \r\n",
        "    # apply encoder\r\n",
        "    outputs = encoder(encoder_inputs)\r\n",
        "    pooled_output = outputs[\"pooled_output\"]  # creates [batch_size, 768].\r\n",
        "    #  sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\r\n",
        "\r\n",
        "    return pooled_output  #, sequence_output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnx-xNf0S4Hw"
      },
      "source": [
        "def create_model():\r\n",
        "\r\n",
        "    # text input layer\r\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.int32)\r\n",
        "\r\n",
        "    # RNN netowrk\r\n",
        "    x = tf.keras.layers.Bidirectional(\r\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True))(encoded_inputs)\r\n",
        "    x = tf.keras.layers.LSTM(64, return_sequences=True)(x)\r\n",
        "    outputs = tf.keras.layers.Dense(10)(x)\r\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    # compiler\r\n",
        "    model.compile(\r\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "        optimizer=\"sgd\",\r\n",
        "        metrics=[\"accuracy\"],\r\n",
        "        )\r\n",
        "    \r\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDkXB7kJfrPz"
      },
      "source": [
        "#Pre-Processor\r\n",
        "\r\n",
        "def pre-process_text():\r\n",
        "\r\n",
        "    # load data\r\n",
        "    train_df, test_df, valid_df = load_and_split_csv(select_column=False)\r\n",
        "    \r\n",
        "    # prep text\r\n",
        "    clean_text(train_df, column='Content', dropna=True)\r\n",
        "    # clean_text(test_df, column='Content', dropna=True)\r\n",
        "    # clean_text(test_df, column='Content', dropna=True)\r\n",
        "\r\n",
        "    X_train, y_train = split_x_y(train_df)\r\n",
        "    # X_test, y_test = split_x_y(test_df)\r\n",
        "    # X_valid, y_valid = split_x_y(valid_df)\r\n",
        "\r\n",
        "    # word embedding / BERT encoder\r\n",
        "    # text input layer\r\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\r\n",
        "\r\n",
        "    # word embedding (BERT model)\r\n",
        "    encoded_inputs = tf.data.Dataset.map(lambda x: BERT_encoding_layer()(x))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}